{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redefine = pd.read_csv('./ariel_project_data_1Kdays.csv')\n",
    "df_tagged = pd.read_json('./etherscan-tagged-data.json')\n",
    "print(df_redefine.head())\n",
    "df_tagged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redefine['other_contracts'] = df_redefine['other_contracts'].apply(lambda x: x.replace(\"'\",'\"'))\n",
    "df_redefine['other_contracts'] = df_redefine['other_contracts'].apply(lambda x: json.loads(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_contracts(obj):\n",
    "    x=[]\n",
    "    for address in obj:\n",
    "        y = address['smartContract']['address']['address']\n",
    "        x.append(y)\n",
    "    return x\n",
    "\n",
    "df_redefine['other_created_address'] = df_redefine['other_contracts'].apply(lambda x: parse_contracts(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redefine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redefine_expanded = df_redefine.loc[:,['token_creator','other_created_address','project_name']]\n",
    "df_redefine_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redefine_expanded = df_redefine_expanded.explode('other_created_address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redefine_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_etherscan = df_tagged.transpose()\n",
    "df_etherscan.reset_index(inplace=True)\n",
    "df_etherscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_redefine_expanded, df_etherscan, left_on=\"other_created_address\",right_on=\"index\", how=\"left\")\n",
    "df_is_tagged = df_merge.loc[df_merge['index'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_redefine_expanded.drop_duplicates('other_created_address'))\n",
    "len(df_etherscan.drop_duplicates('index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_is_tagged.set_index('index', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_is_tagged.drop('other_created_address', axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokens analyzed: %s\"%(len(df_redefine)))\n",
    "print(\"Num of contracts created by token creator: %s\"%(len(df_redefine_expanded)))\n",
    "print(\"Tagged contracts analyzed: %s\"%(len(df_etherscan)))\n",
    "print(\"Num of created contracts that are tagged: %s\"%(len(df_merge.loc[df_merge['index'].notna()])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen - there is very few common contracts between the Redefine DF and Etherscan tagged data. \n",
    "To overcome this we will filter out contracts that haven't been used in the past year."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional ways for us to increase validation of contracts:\n",
    "1. Scrape Etherscan up to date V\n",
    "2. Add a date threshold \n",
    "3. Call contract name + call name function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_is_tagged.to_csv('first_results.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will verify from the tagged Etherscan names which are correct and which are incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = df_is_tagged.drop_duplicates('project_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = [\"token\",\n",
    "\"proxy\",\n",
    "\"contract\",\n",
    "\"work\",\n",
    "\"protocol\",\n",
    "\"governance\",\n",
    "\"dao\",\n",
    "\"finance\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_name(p_name, labels,name):\n",
    "    project_name = p_name.split()\n",
    "    print(project_name)\n",
    "    for name in project_name:\n",
    "        if name in remove_words:\n",
    "            project_name.remove(name)\n",
    "    print(project_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_is_tagged['verified'] = df_is_tagged['project_name','labels','name'].apply(lambda x: verify_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spell', '(spell)']\n"
     ]
    }
   ],
   "source": [
    "def verify_name(p_name, labels,name):\n",
    "    project_name = p_name.split()\n",
    "    lower_project_name = []\n",
    "    for name in project_name:\n",
    "        name = name.lower()\n",
    "        name = name.\n",
    "        lower_project_name.append(name)\n",
    "        if name in remove_words:\n",
    "            lower_project_name.remove(name)\n",
    "    print(lower_project_name)\n",
    "\n",
    "verify_name('Spell Token (SPELL)','','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariel-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5189f02553a516c04daa42a4c3a30d48a304463063ad5ec13130d72eb942a4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
