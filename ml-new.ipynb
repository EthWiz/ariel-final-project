{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('./raw_data/ml_data_new.csv', index_col=0)\n",
    "data = data.loc[:,['last_tx_in_days','date_creation_diff','gas','gas_price','is_published','verified']]\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['verified'])\n",
    "y = data['verified']\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating train, validation and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Parameter tuning for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'max_samples': 30,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [2,3,5,7],\n",
    "    'max_samples':[30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with RandomForestClassifier\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), \n",
    "                       param_grid_rf, \n",
    "                       cv=5, \n",
    "                       scoring='f1')\n",
    "\n",
    "# Fit GridSearchCV for Random Forest\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters for Random Forest\n",
    "best_params_rf = grid_rf.best_params_\n",
    "best_params_rf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Parameter tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 300}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with XGBoost\n",
    "grid_xgb = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "                        param_grid_xgb, \n",
    "                        cv=5, \n",
    "                        scoring='f1')\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters for XGBoost\n",
    "best_params_xgb = grid_xgb.best_params_\n",
    "best_params_xgb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating diffrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.87202</td>\n",
       "      <td>0.823110</td>\n",
       "      <td>0.894098</td>\n",
       "      <td>0.852765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.87082</td>\n",
       "      <td>0.818616</td>\n",
       "      <td>0.894153</td>\n",
       "      <td>0.849214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.81384</td>\n",
       "      <td>0.712079</td>\n",
       "      <td>0.917377</td>\n",
       "      <td>0.731724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.84499</td>\n",
       "      <td>0.766522</td>\n",
       "      <td>0.927432</td>\n",
       "      <td>0.776233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.84554</td>\n",
       "      <td>0.784525</td>\n",
       "      <td>0.847869</td>\n",
       "      <td>0.864331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  F1-score  Accuracy    Recall  Precision\n",
       "0        Random Forest   0.87202  0.823110  0.894098   0.852765\n",
       "1              XGBoost   0.87082  0.818616  0.894153   0.849214\n",
       "2  Logistic Regression   0.81384  0.712079  0.917377   0.731724\n",
       "3                  SVM   0.84499  0.766522  0.927432   0.776233\n",
       "4        Decision Tree   0.84554  0.784525  0.847869   0.864331"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier(**best_params_rf)),\n",
    "    ('XGBoost',XGBClassifier(use_label_encoder=False, eval_metric='logloss', **best_params_xgb)),\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('SVM', SVC()),\n",
    "    ('Decision Tree', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "# Initialize scoring metrics\n",
    "scoring = {\n",
    "    'F1-score': make_scorer(f1_score),\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'Precision': make_scorer(precision_score)\n",
    "}\n",
    "\n",
    "# Initialize KFold cross-validator\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "results = []\n",
    "\n",
    "# For each model\n",
    "for name, model in models:\n",
    "    # Initialize metric storage for current model\n",
    "    current_results = {'Model': name}\n",
    "    # For each metric\n",
    "    for score_name, scorer in scoring.items():\n",
    "        # Calculate mean metric score over 5 folds\n",
    "        score = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scorer).mean()\n",
    "        # Store score\n",
    "        current_results[score_name] = score\n",
    "    # Add current model's results to overall results\n",
    "    results.append(current_results)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the best model with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: Random Forest\n",
      "Test F1-score: 0.8792270531400966\n",
      "Test Accuracy: 0.831081081081081\n",
      "Test Recall: 0.91\n",
      "Test Precision: 0.8504672897196262\n"
     ]
    }
   ],
   "source": [
    "# Find the model with the highest F1-score\n",
    "best_model_name = results_df.loc[results_df['F1-score'].idxmax(), 'Model']\n",
    "\n",
    "# Find the corresponding model in the models list\n",
    "best_model = next((model for name, model in models if name == best_model_name), None)\n",
    "\n",
    "# Fit the best model on the training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the metrics on the test data\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "print(f'\\nBest model: {best_model_name}')\n",
    "print(f'Test F1-score: {test_f1}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test Precision: {test_precision}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariel-ml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
